<!DOCTYPE html>
<html>
<head>

  <style> .results-carousel .item img { width: 512px; height: 512px; } </style>
  <meta charset="utf-8">
  <meta name="description"
        content="MotionMaster: Training-free Camera Motion Transfer For Video Generation">
  <meta name="keywords" content="Video Generation, Camera Motion transfer, Camera-Object Motion, Disentanglement">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MotionMaster: Training-free Camera Motion Transfer For Video Generation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">UltraGen: High-Resolution Video Generation with Hierarchical Attention</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://sjtuplayer.github.io/">Teng Hu</a><sup>1*</sup>,</span>
              <span class="author-block">
                <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>2*</sup>,</span>
              <span class="author-block">
                <a>Zihan Su</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://yiranran.github.io/">Ran Yi</a><sup>1#</sup>,
              </span>
              <!-- <span class="author-block">
                <a>Yating Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a>Hongrui Huang</a><sup>3</sup>,
              </span>
              <br />
              <span class="author-block">
                <a > Jieyu Weng</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a>Yabiao Wang</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a >Lizhuang Ma</a><sup>1</sup>
              </span> -->
              <!-- <span class="author-block">
                <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
              </span> -->
            </div>
  
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Washington,</span>
              <span class="author-block"><sup>2</sup>Google Research</span>
            </div> -->
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University, Shanghai, China</span><br />
              <span class="author-block"><sup>2</sup>Zhejiang University, Shanghai, China </span><br />
              <!-- <span class="author-block"><sup>3</sup>Harbin Institute of Technology, Harbin, China </span> -->
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2404.15789.pdf"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2404.15789"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
<!--                <span class="link-block">-->
<!--                  <a href="https://github.com/sjtuplayer/MotionMaster"-->
<!--                     class="external-link button is-normal is-rounded is-dark">-->
<!--                    <span class="icon">-->
<!--                        <i class="fab fa-github"></i>-->
<!--                    </span>-->
<!--                    <span>Code</span>-->
<!--                    </a>-->
<!--                </span>-->
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                    </a> -->
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="section" id="teaser">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">
            4k Video Generation
          </h3>
          <div class="item">
<!--            <video id="teaser" autoplay controls muted loop playsinline height="100%">-->
<!--              <source src="./static/videos/teaser.mp4"-->
<!--                      type="video/mp4">-->
<!--            </video>-->
<!--            <img src="./static/my_images/teaser.gif" alt="GIF 1" autoplay loop playsinline height="100%">-->
<iframe width="1024" height="576" src="https://www.youtube.com/embed/lcN9QyeCIv0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      </div>
  </div>
</section>

  <section class="section">
      <div class="container is-max-desktop">
<div class="highlights-container">
  <div class="columns is-centered">
      <div class="column is-fulls">
            <div class="columns is-centered has-text-centered">
        <h2 class="title is-3">Highlights</h2>
              </div>
  <div class="highlight-item">
    <p><strong>(1) Breakthrough Resolution Capability:</strong>
    As the first model to achieve native high-quality 4K video generation, UltraGen seamlessly scales pre-trained low-resolution (≤720P) video diffusion models to 1080P/2K/4K, eliminating the "pseudo-high-resolution" limitation of traditional super-resolution pipelines. It delivers authentic, detail-rich content that outperforms state-of-the-art methods in both 1080P and 4K tasks.</p>
  </div>

  <div class="highlight-item">
    <p><strong>(2) Efficient Hierarchical Dual-Branch Attention:</strong>
    UltraGen innovatively decouples full attention into local and global branches to solve the quadratic computational bottleneck of diffusion transformers. The local branch focuses on fine-grained regional details, while the global branch ensures semantic consistency—all with a hierarchical design that avoids the O((T·H·W)²) complexity of traditional models.</p>
  </div>

  <div class="highlight-item">
    <p><strong>(3) Computational Efficiency & Speed Advantage:</strong>
    With its spatially compressed global modeling and cross-window local attention, UltraGen achieves a 4.78× speedup for 4K video generation and 2.69× speedup for 1080P generation compared to the popular Wan-T2V-1.3B baseline. It makes high-resolution video training and inference feasible without excessive hardware costs.</p>
  </div>

  <div class="highlight-item">
    <p><strong>(4) Superior Quality Across Metrics:</strong>
    In quantitative evaluations, UltraGen sets new standards:
    Lowest HD-FVD (214.12 for 1080P, 424.61 for 4K) for high-res similarity to real videos;
    Highest HD-MSE (390.19 for 1080P, 386.01 for 4K) and HD-LPIPS (0.5455 for 1080P, 0.6450 for 4K) for fine-grained details;
      temporal consistency (0.9827 for 1080P) and top CLIP scores among native high-res generators, ensuring prompt alignment and smooth frame transitions.</p>
  </div>


        </div>
</div>
  </div>
        </div>
    </section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fulls">

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in video generation have made it possible to produce visually compelling videos, with wide-ranging applications in content creation, entertainment, and virtual reality.
However, most existing diffusion transformer based video generation models are limited to low-resolution outputs (≤720P) due to the quadratic computational complexity of the attention mechanism with respect to
the output width and height.
This computational bottleneck makes native high-resolution video generation (1080P/2K/4K) impractical for both training and inference.
To address this challenge, we present <b>UltraGen</b>, a novel video generation framework that enables <b><em>i) efficient</em> and <em>ii) end-to-end native high-resolution</em> </b>video synthesis.
Specifically, UltraGen features a hierarchical dual-branch attention architecture based on global-local attention decomposition, which decouples full attention into a local attention branch for high-fidelity regional content and a global attention branch for overall semantic consistency.
We further propose a spatially compressed global modeling strategy to efficiently learn global dependencies, and a hierarchical cross-window local attention mechanism to reduce computational costs while enhancing information flow across different local windows.
Extensive experiments demonstrate that UltraGen can effectively scale pre-trained low-resolution video models to 1080P and even 4K resolution for the first time, outperforming existing state-of-the-art methods and super-resolution based two-stage pipelines in both qualitative and quantitative evaluations.
          </p>
            
        </div>
        <div class="columns is-centered">
          <img src="./static/my_images/teaser.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fulls">

        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <p>
            Overview of our UltraGen that decomposes the full-attention into a global attention branch for overall semantic consistency and a local attention branch for high-fidelity regional content, boosting high-efficiency and high-resolution video generation.
            </p>

        </div>
        <div class="columns is-centered">
          <img src="./static/my_images/Framework.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
      </div>
    </div>
  </div>
</section>


  <section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fulls">

        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <p>
            Comparison results of existing state-of-the-art video generation methods on 1080P video generation.
            The red boxes highlight zoomed-in regions, where our model produces the clearest high-resolution videos with the most fine-grained details.
            </p>

        </div>
        <div class="columns is-centered">
          <img src="./static/my_images/compare1.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
      </div>
    </div>
  </div>
</section>

  <section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-fulls">

        <h2 class="title is-3">Framework</h2>
        <div class="content has-text-justified">
          <p>
            Quantitative comparisons. Our UltraGen demonstrates superior high-quality HD video generation capabilities.
            Bold indicates the best performance and * indicates the best performance among all the non-SR methods.
            </p>

        </div>
        <div class="columns is-centered">
          <img src="./static/my_images/compare2.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <div class="container has-text-centered">
  <p><strong>Our demo is divided into two parts: firstly, <a href="#experimental-results" class="highlighted-link">all our experimental results</a>, and secondly, we provide a <a href="#gallery" class="highlighted-link">gallery to showcase various effects</a>.</strong></p>
</div> -->
<!-- 
<section class="section" id="experimental-results">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">
            Source Video & Swap Attention Map
          </h3>
          <p>
            We find that the temporal attention maps determine the generated video motions. By switching the temporal attention maps between the two videos in the first row, we
            have the results in the second row, whose videos motions are totally swithed.
          </p>
          <div class="item">
            <img src="./static/videos/fix_1-ezgif.com-loop-count.gif" alt="GIF 1">
          </div>
        </div>
      </div>
      </div>
  </div>
</section> -->


<!-- <div>
  <div class="column has-text-centered" id="gallery">
    <h2 class="title is-3">Gallery</h2>
  </div>
</div> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://arxiv.org/pdf/2404.15789.pdf">
        <svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
      </a>
      <a class="icon-link" href="https://github.com/sjtuplayer/MotionMaster" disabled="">
        <svg class="svg-inline--fa fa-github fa-w-16" aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512" data-fa-i2svg=""><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for our website.
            We sincerely appreciate Nerfies authors for their awesome templates.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
